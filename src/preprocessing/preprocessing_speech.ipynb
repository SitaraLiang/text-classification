{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5131acea",
   "metadata": {},
   "source": [
    "# Preprocessing Speech (Chirac/Mitterrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9614df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daeaf41",
   "metadata": {},
   "source": [
    "## Load text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f951becb",
   "metadata": {},
   "source": [
    "alllabs: \n",
    "- 1: Chirac\n",
    "- -1: Mitterrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0971857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57413\n",
      " A Brazzaville, que l'Afrique de demain se dessine.\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME = \"../../dataset/corpus.tache1.learn.utf8\"\n",
    "\n",
    "alltxts, alllabs = load_pres(FILE_NAME)\n",
    "\n",
    "print(len(alltxts))\n",
    "print(alltxts[10])\n",
    "print(alllabs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075910a6",
   "metadata": {},
   "source": [
    "## Remove Numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133ee72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_txts = remove_numbers(alltxts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d3569d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top uninformative words (appear equally in both classes):\n",
      "secteurs            : ratio=1.000, class1=0.0025, class2=0.0025\n",
      "avec                : ratio=1.000, class1=0.0856, class2=0.0856\n",
      "annee               : ratio=0.999, class1=0.0128, class2=0.0128\n",
      "periode             : ratio=0.999, class1=0.0029, class2=0.0029\n",
      "equipements         : ratio=0.999, class1=0.0015, class2=0.0015\n",
      "contact             : ratio=0.999, class1=0.0011, class2=0.0011\n",
      "exercer             : ratio=0.998, class1=0.0019, class2=0.0019\n",
      "chances             : ratio=0.998, class1=0.0037, class2=0.0037\n",
      "plein               : ratio=0.998, class1=0.0017, class2=0.0017\n",
      "troisieme           : ratio=0.997, class1=0.0027, class2=0.0027\n",
      "britannique         : ratio=0.995, class1=0.0007, class2=0.0007\n",
      "siege               : ratio=0.995, class1=0.0007, class2=0.0007\n",
      "complementarite     : ratio=0.995, class1=0.0007, class2=0.0007\n",
      "calendrier          : ratio=0.995, class1=0.0007, class2=0.0007\n",
      "ancien              : ratio=0.995, class1=0.0013, class2=0.0013\n",
      "oppression          : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "prolongement        : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "approches           : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "orienter            : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "qualifiee           : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "excellente          : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "reprises            : ratio=0.995, class1=0.0008, class2=0.0008\n",
      "voiture             : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "limite              : ratio=0.995, class1=0.0008, class2=0.0008\n",
      "concret             : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "etendre             : ratio=0.995, class1=0.0008, class2=0.0008\n",
      "immediatement       : ratio=0.995, class1=0.0008, class2=0.0008\n",
      "menacent            : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "preoccupation       : ratio=0.995, class1=0.0012, class2=0.0012\n",
      "candidature         : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "art                 : ratio=0.995, class1=0.0032, class2=0.0032\n",
      "bouleverse          : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "budgetaire          : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "automobile          : ratio=0.995, class1=0.0008, class2=0.0008\n",
      "inevitable          : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "demarche            : ratio=0.995, class1=0.0036, class2=0.0036\n",
      "prochains           : ratio=0.995, class1=0.0008, class2=0.0008\n",
      "rues                : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "remerciements       : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "occupent            : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "conforme            : ratio=0.995, class1=0.0008, class2=0.0008\n",
      "but                 : ratio=0.995, class1=0.0008, class2=0.0008\n",
      "suisse              : ratio=0.995, class1=0.0004, class2=0.0004\n",
      "representants       : ratio=0.994, class1=0.0042, class2=0.0043\n",
      "creer               : ratio=0.994, class1=0.0062, class2=0.0061\n",
      "relations           : ratio=0.993, class1=0.0103, class2=0.0102\n",
      "soir                : ratio=0.993, class1=0.0045, class2=0.0045\n",
      "prend               : ratio=0.992, class1=0.0021, class2=0.0021\n",
      "universites         : ratio=0.991, class1=0.0017, class2=0.0017\n",
      "adopte              : ratio=0.991, class1=0.0009, class2=0.0009\n",
      "lumiere             : ratio=0.991, class1=0.0009, class2=0.0009\n",
      "apporte             : ratio=0.991, class1=0.0037, class2=0.0037\n",
      "actif               : ratio=0.991, class1=0.0009, class2=0.0009\n",
      "complete            : ratio=0.991, class1=0.0009, class2=0.0009\n",
      "pratiques           : ratio=0.990, class1=0.0013, class2=0.0013\n",
      "majeur              : ratio=0.989, class1=0.0023, class2=0.0023\n",
      "organisee           : ratio=0.989, class1=0.0012, class2=0.0012\n",
      "organismes          : ratio=0.989, class1=0.0012, class2=0.0012\n",
      "strategique         : ratio=0.989, class1=0.0012, class2=0.0012\n",
      "espaces             : ratio=0.989, class1=0.0012, class2=0.0012\n",
      "hongrie             : ratio=0.988, class1=0.0009, class2=0.0009\n",
      "faisant             : ratio=0.988, class1=0.0019, class2=0.0019\n",
      "formation           : ratio=0.987, class1=0.0090, class2=0.0089\n",
      "interet             : ratio=0.987, class1=0.0084, class2=0.0085\n",
      "conduire            : ratio=0.987, class1=0.0029, class2=0.0029\n",
      "prochaines          : ratio=0.986, class1=0.0017, class2=0.0017\n",
      "portee              : ratio=0.984, class1=0.0026, class2=0.0025\n",
      "capacites           : ratio=0.984, class1=0.0026, class2=0.0025\n",
      "acquis              : ratio=0.984, class1=0.0025, class2=0.0025\n",
      "montre              : ratio=0.983, class1=0.0035, class2=0.0036\n",
      "gravite             : ratio=0.982, class1=0.0005, class2=0.0005\n",
      "perennite           : ratio=0.982, class1=0.0005, class2=0.0005\n",
      "africains           : ratio=0.982, class1=0.0022, class2=0.0021\n",
      "reunies             : ratio=0.982, class1=0.0005, class2=0.0005\n",
      "priorites           : ratio=0.982, class1=0.0022, class2=0.0021\n",
      "principes           : ratio=0.982, class1=0.0061, class2=0.0062\n",
      "assurer             : ratio=0.981, class1=0.0079, class2=0.0077\n",
      "age                 : ratio=0.980, class1=0.0023, class2=0.0023\n",
      "impots              : ratio=0.980, class1=0.0013, class2=0.0013\n",
      "argentine           : ratio=0.980, class1=0.0013, class2=0.0013\n",
      "armes               : ratio=0.980, class1=0.0026, class2=0.0027\n",
      "article             : ratio=0.980, class1=0.0005, class2=0.0005\n",
      "motif               : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "horizons            : ratio=0.980, class1=0.0005, class2=0.0005\n",
      "ouvertes            : ratio=0.980, class1=0.0005, class2=0.0005\n",
      "originalite         : ratio=0.980, class1=0.0005, class2=0.0005\n",
      "apportez            : ratio=0.980, class1=0.0005, class2=0.0005\n",
      "camp                : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "gouvernementales    : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "brutale             : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "camarades           : ratio=0.980, class1=0.0005, class2=0.0005\n",
      "annulation          : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "malaise             : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "palestinien         : ratio=0.980, class1=0.0005, class2=0.0005\n",
      "actionnaires        : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "frappes             : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "normandie           : ratio=0.980, class1=0.0005, class2=0.0005\n",
      "conciliation        : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "revanche            : ratio=0.980, class1=0.0008, class2=0.0008\n",
      "scolarite           : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "traits              : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "fonctionnaire       : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "decentralisee       : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "maitriser           : ratio=0.980, class1=0.0018, class2=0.0019\n",
      "eloignee            : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "commissions         : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "douloureux          : ratio=0.980, class1=0.0005, class2=0.0005\n",
      "entierement         : ratio=0.980, class1=0.0005, class2=0.0005\n",
      "evoquee             : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "bleus               : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "lointain            : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "medicaux            : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "systemes            : ratio=0.980, class1=0.0018, class2=0.0019\n",
      "assurances          : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "multilaterale       : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "sympathique         : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "pedagogique         : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "reequilibrage       : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "materielles         : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "loisirs             : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "poetes              : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "referendum          : ratio=0.980, class1=0.0005, class2=0.0005\n",
      "montrent            : ratio=0.980, class1=0.0010, class2=0.0011\n",
      "commissariat        : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "elimination         : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "histoires           : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "sursaut             : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "agro                : ratio=0.980, class1=0.0005, class2=0.0005\n",
      "fondements          : ratio=0.980, class1=0.0008, class2=0.0008\n",
      "retrouvons          : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "construite          : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "realisme            : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "principalement      : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "intervenu           : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "secheresse          : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "participants        : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "conjonction         : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "condamnes           : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "sacrifices          : ratio=0.980, class1=0.0008, class2=0.0008\n",
      "ajustement          : ratio=0.980, class1=0.0003, class2=0.0003\n",
      "deux                : ratio=0.979, class1=0.0294, class2=0.0300\n",
      "seconde             : ratio=0.978, class1=0.0012, class2=0.0012\n",
      "personnalite        : ratio=0.978, class1=0.0012, class2=0.0012\n",
      "et                  : ratio=0.978, class1=0.6512, class2=0.6370\n",
      "permettra           : ratio=0.977, class1=0.0032, class2=0.0033\n",
      "dela                : ratio=0.977, class1=0.0092, class2=0.0094\n",
      "programmes          : ratio=0.976, class1=0.0025, class2=0.0025\n",
      "leur                : ratio=0.975, class1=0.0660, class2=0.0643\n",
      "obstacles           : ratio=0.975, class1=0.0014, class2=0.0013\n",
      "toutes              : ratio=0.975, class1=0.0262, class2=0.0255\n",
      "nationaux           : ratio=0.974, class1=0.0017, class2=0.0017\n",
      "largement           : ratio=0.974, class1=0.0029, class2=0.0028\n",
      "venu                : ratio=0.973, class1=0.0044, class2=0.0043\n",
      "reconciliation      : ratio=0.973, class1=0.0022, class2=0.0021\n",
      "doter               : ratio=0.972, class1=0.0012, class2=0.0012\n",
      "scientifique        : ratio=0.971, class1=0.0032, class2=0.0033\n",
      "dimension           : ratio=0.971, class1=0.0032, class2=0.0033\n",
      "mettre              : ratio=0.971, class1=0.0092, class2=0.0094\n",
      "distinction         : ratio=0.970, class1=0.0008, class2=0.0008\n",
      "places              : ratio=0.969, class1=0.0009, class2=0.0009\n",
      "competence          : ratio=0.969, class1=0.0026, class2=0.0025\n",
      "humain              : ratio=0.968, class1=0.0024, class2=0.0025\n",
      "planete             : ratio=0.968, class1=0.0027, class2=0.0027\n",
      "etrangers           : ratio=0.968, class1=0.0015, class2=0.0016\n",
      "drames              : ratio=0.967, class1=0.0010, class2=0.0009\n",
      "engagent            : ratio=0.967, class1=0.0010, class2=0.0009\n",
      "dessine             : ratio=0.967, class1=0.0010, class2=0.0009\n",
      "etudes              : ratio=0.967, class1=0.0019, class2=0.0019\n",
      "banques             : ratio=0.965, class1=0.0006, class2=0.0007\n",
      "comprehension       : ratio=0.965, class1=0.0013, class2=0.0013\n",
      "allait              : ratio=0.965, class1=0.0006, class2=0.0007\n",
      "bruxelles           : ratio=0.965, class1=0.0006, class2=0.0007\n",
      "new                 : ratio=0.965, class1=0.0006, class2=0.0007\n",
      "attirer             : ratio=0.965, class1=0.0006, class2=0.0007\n",
      "atteinte            : ratio=0.965, class1=0.0006, class2=0.0007\n",
      "financements        : ratio=0.965, class1=0.0006, class2=0.0007\n",
      "entraine            : ratio=0.965, class1=0.0006, class2=0.0007\n",
      "respectees          : ratio=0.965, class1=0.0006, class2=0.0007\n",
      "etrangeres          : ratio=0.965, class1=0.0019, class2=0.0020\n",
      "sang                : ratio=0.965, class1=0.0011, class2=0.0011\n",
      "facteur             : ratio=0.965, class1=0.0011, class2=0.0011\n",
      "souffrances         : ratio=0.965, class1=0.0011, class2=0.0011\n",
      "chacun              : ratio=0.963, class1=0.0214, class2=0.0222\n",
      "obligation          : ratio=0.963, class1=0.0012, class2=0.0012\n",
      "contraire           : ratio=0.962, class1=0.0027, class2=0.0028\n",
      "quartiers           : ratio=0.961, class1=0.0020, class2=0.0021\n",
      "peur                : ratio=0.961, class1=0.0010, class2=0.0011\n",
      "reunir              : ratio=0.961, class1=0.0010, class2=0.0011\n",
      "hautes              : ratio=0.961, class1=0.0014, class2=0.0013\n",
      "elle                : ratio=0.961, class1=0.0768, class2=0.0738\n",
      "desormais           : ratio=0.961, class1=0.0086, class2=0.0082\n",
      "internationales     : ratio=0.961, class1=0.0034, class2=0.0036\n",
      "societe             : ratio=0.960, class1=0.0188, class2=0.0181\n",
      "tient               : ratio=0.960, class1=0.0024, class2=0.0025\n",
      "chomage             : ratio=0.960, class1=0.0049, class2=0.0051\n",
      "precedent           : ratio=0.960, class1=0.0014, class2=0.0015\n",
      "prendre             : ratio=0.959, class1=0.0096, class2=0.0092\n",
      "fonds               : ratio=0.959, class1=0.0032, class2=0.0031\n",
      "avancer             : ratio=0.959, class1=0.0017, class2=0.0016\n",
      "pour                : ratio=0.959, class1=0.2072, class2=0.2161\n",
      "perspective         : ratio=0.959, class1=0.0018, class2=0.0019\n",
      "lance               : ratio=0.958, class1=0.0022, class2=0.0023\n",
      "assure              : ratio=0.958, class1=0.0022, class2=0.0023\n",
      "francaise           : ratio=0.958, class1=0.0130, class2=0.0136\n",
      "adoptees            : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "jusque              : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "citoyens            : ratio=0.955, class1=0.0053, class2=0.0056\n",
      "exil                : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "voix                : ratio=0.955, class1=0.0027, class2=0.0028\n",
      "avancee             : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "achat               : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "individuel          : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "imaginaire          : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "manquent            : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "disponible          : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "collectivite        : ratio=0.955, class1=0.0019, class2=0.0020\n",
      "approfondie         : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "academie            : ratio=0.955, class1=0.0008, class2=0.0008\n",
      "comptables          : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "modifie             : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "haleine             : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "ouvrages            : ratio=0.955, class1=0.0004, class2=0.0004\n",
      "personnes           : ratio=0.955, class1=0.0057, class2=0.0060\n",
      "heureuse            : ratio=0.955, class1=0.0011, class2=0.0012\n",
      "afin                : ratio=0.955, class1=0.0053, class2=0.0051\n",
      "membres             : ratio=0.955, class1=0.0053, class2=0.0051\n",
      "etudiants           : ratio=0.954, class1=0.0028, class2=0.0027\n",
      "nom                 : ratio=0.954, class1=0.0619, class2=0.0590\n",
      "aux                 : ratio=0.953, class1=0.0730, class2=0.0695\n",
      "contribuer          : ratio=0.953, class1=0.0028, class2=0.0029\n",
      "puissent            : ratio=0.953, class1=0.0028, class2=0.0029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uninformative_words = find_uninformative_words(processed_txts, alllabs, threshold=0.95)\n",
    "len(uninformative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6876cc3d",
   "metadata": {},
   "source": [
    "## Vectorize with TfidfVectorizer\n",
    "\n",
    "**TF-IDF**: words can also be weighted by importance.  \n",
    "Corpus: $C = \\{\\mathbf d_{1}, \\ldots, \\mathbf d_{|C|}\\}$, vocabulary: $V = \\{\\mathbf w_{1}, \\ldots, \\mathbf w_{|V|}\\}$:\n",
    "\n",
    "- $\\mathbf{d}_{ik}^{(tf)}$ term frequency for word $w_k$ in document $d_i$, s.t. $\\sum_{k=1}^{|V|} d_{ik}^{(tf)} = 1$  \n",
    "- $\\mathrm{df}_{k}$ document frequency: $\\mathrm{df}_{k} = \\frac{|\\{\\mathbf d : w_{k} \\in \\mathbf d\\}|}{|C|}$\n",
    "\n",
    "TF-IDF for word $w_k$ in document $d_i$:\n",
    "\n",
    "$$\n",
    "d_{ik}^{(tfidf)} = d_{ik}^{(tf)} \\, \\log \\frac{1}{\\mathrm{df}_{k}}\n",
    "$$\n",
    "\n",
    "**Main parameters:**\n",
    "- **use_idf:** boolean, default=True.  \n",
    "- **smooth_idf:** Smooth idf weights, default=True. Adds one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents division by zero.  \n",
    "- **sublinear_tf:** boolean, default=False. Apply sublinear tf scaling, i.e., replace $d_{ik}^{(tf)}$ with $1 + \\log(d_{ik}^{(tf)})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064f3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get French stopwords as a list\n",
    "french_stopwords = stopwords.words('french') + uninformative_words\n",
    "# Remove their accents\n",
    "french_stopwords_no_accents = [remove_accents(word) for word in french_stopwords]\n",
    "#french_stopwords_stemmed = stemming_french(french_stopwords_no_accents)\n",
    "\n",
    "# ATTENTION: one sentence = one doc\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,           # handles capitalization\n",
    "    stop_words=french_stopwords_no_accents,     # removes stop words (Pass the stop words list)\n",
    "    max_df=0.80,             # ignore terms in >95% of docs\n",
    "    min_df=15,                # ignore terms in <2 docs\n",
    "    ngram_range=(1, 2),       # unigrams + bigrams,\n",
    "    strip_accents='unicode'  # handles accents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0633d711",
   "metadata": {},
   "source": [
    "## Stemming (Optional)\n",
    "Might hurt performance, test if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ca3f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_txts = stemming_french(alltxts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24fa8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(processed_txts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8339164d",
   "metadata": {},
   "source": [
    "**n_features is vocaburary**: unique words across all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135af68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (57413, 6990)\n",
      "['abandon' 'abandonner' 'abord' 'abord avant' 'abord dire'\n",
      " 'abord monsieur' 'abord parce' 'abord remercier' 'abord saluer' 'aborde']\n"
     ]
    }
   ],
   "source": [
    "# X is a sparse matrix\n",
    "print(\"Shape of X:\", X.shape)  # (n_documents, n_features)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(feature_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2904b038",
   "metadata": {},
   "source": [
    "## Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56b938c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45930, 6990)\n",
      "(11483, 6990)\n",
      "45930\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rs=10\n",
    "[X_train, X_test, y_train, y_test]  = train_test_split(X, alllabs, test_size=0.2, random_state=rs, shuffle=True)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(len(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9f54e",
   "metadata": {},
   "source": [
    "## Try on three models\n",
    "- Na誰ve bayes\n",
    "- Logistic Regression\n",
    "- SVM\n",
    "\n",
    "For now just fit each model below with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ad3ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na誰ve Bayes accuracy train=0.8860004354452428, accuracy test=0.8807802838979361\n",
      "Logistic Regression accuracy train=0.9408447637709558, accuracy test=0.8810415396673343\n",
      "SVM accurac ytrain=0.930089266274766, accuracy test=0.8982844204476182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#Na誰ve Bayes\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Logistic Regression\n",
    "t = 1e-8\n",
    "C=100.0\n",
    "lr_clf = LogisticRegression(random_state=0, solver='liblinear',max_iter=100, tol=t, C=C)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "#Linear SVM\n",
    "svm_clf = LinearSVC(random_state=0)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "pred_nbt = nb_clf.predict(X_train)\n",
    "pred_lrt = lr_clf.predict(X_train)\n",
    "pred_svmt = svm_clf.predict(X_train)\n",
    "\n",
    "pred_nb = nb_clf.predict(X_test)\n",
    "pred_lr = lr_clf.predict(X_test)\n",
    "pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"Na誰ve Bayes accuracy train={accuracy_score(y_train, pred_nbt)}, accuracy test={accuracy_score(y_test, pred_nb)}\")\n",
    "print(f\"Logistic Regression accuracy train={accuracy_score(y_train, pred_lrt)}, accuracy test={accuracy_score(y_test, pred_lr)}\")\n",
    "print(f\"SVM accurac ytrain={accuracy_score(y_train, pred_svmt)}, accuracy test={accuracy_score(y_test, pred_svm)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
